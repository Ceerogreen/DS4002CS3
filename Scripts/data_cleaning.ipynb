{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10309860",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import typical data science packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77ee4636",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import and concatenate the data files\n",
    "\n",
    "# Directory containing the CSV files\n",
    "data_dir = r\"../Data/\"\n",
    "# Filenames to be processed\n",
    "all_files = [\n",
    "    \"adm2014_rv.csv\",\n",
    "    \"adm2015_rv.csv\",\n",
    "    \"adm2016_rv.csv\",\n",
    "    \"adm2017_rv.csv\",\n",
    "    \"adm2018_rv.csv\",\n",
    "    \"adm2019_rv.csv\",\n",
    "    \"adm2020_rv.csv\",\n",
    "    \"adm2021_rv.csv\",\n",
    "    \"adm2022_rv.csv\",\n",
    "    \"adm2023.csv\"\n",
    "]\n",
    "\n",
    "# Read and combine all matched CSV files\n",
    "dfs = []\n",
    "for file in all_files:\n",
    "    # Construct full file path\n",
    "    file_path = os.path.join(data_dir, file)\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Extract the four digits in the filename\n",
    "    \n",
    "    match = re.search(r'(\\d{4})', file)\n",
    "    if match:\n",
    "        df['year'] = match.group(1)\n",
    "    else:\n",
    "        df['year'] = None\n",
    "    # Clean white space out of column names\n",
    "    df.columns = df.columns.str.strip()\n",
    "    dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00c299af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     20575\n",
       "unique       10\n",
       "top        2014\n",
       "freq       2236\n",
       "Name: year, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick description of the combined data\n",
    "combined_df['year'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38e60d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do basic cleaning of the combined data\n",
    "# Drop duplicates\n",
    "combined_df.drop_duplicates(inplace=True)\n",
    "# Drop rows with missing UNITID\n",
    "combined_df.dropna(subset=['UNITID'], inplace=True)\n",
    "# Ensure UNITID is integer\n",
    "combined_df['UNITID'] = combined_df['UNITID'].astype(int)\n",
    "# Reset index after cleaning\n",
    "combined_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9cfa4733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'XSATWR25' is all null in years: ['2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
      "Column 'SATWR25' is all null in years: ['2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
      "Column 'XSATWR75' is all null in years: ['2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
      "Column 'SATWR75' is all null in years: ['2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
      "Column 'XACTWR25' is all null in years: ['2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
      "Column 'ACTWR25' is all null in years: ['2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
      "Column 'XACTWR75' is all null in years: ['2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
      "Column 'ACTWR75' is all null in years: ['2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
      "Column 'ADMCON10' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'ADMCON11' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'ADMCON12' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'XAPPLCNAN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'APPLCNAN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'XAPPLCNUN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'APPLCNUN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'XADMSSNAN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'ADMSSNAN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'XADMSSNUN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'ADMSSNUN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'XENRLAN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'ENRLAN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'XENRLUN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'ENRLUN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'XENRLFTAN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'ENRLFTAN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'XENRLFTUN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'ENRLFTUN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'XENRLPTAN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'ENRLPTAN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'XENRLPTUN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'ENRLPTUN' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'XSATVR50' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'SATVR50' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'XSATMT50' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'SATMT50' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'XACTCM50' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'ACTCM50' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'XACTEN50' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'ACTEN50' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'XACTMT50' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
      "Column 'ACTMT50' is all null in years: ['2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n"
     ]
    }
   ],
   "source": [
    "## Look at which observations are not recorded at all in certain years\n",
    "\n",
    "# For each column, find years where all entries are null for that column\n",
    "null_years = {}\n",
    "for col in combined_df.columns:\n",
    "    # Group by year and check if all values in the column are null for each year\n",
    "    years_all_null = combined_df.groupby('year')[col].apply(lambda x: x.isnull().all())\n",
    "    # Get years where all values are null\n",
    "    null_years[col] = years_all_null[years_all_null].index.tolist()\n",
    "\n",
    "# Display columns with at least one year where all entries are null\n",
    "for col, years in null_years.items():\n",
    "    if years:\n",
    "        print(f\"Column '{col}' is all null in years: {years}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12a21b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import and concatenate the characteristic files\n",
    "\n",
    "# Directory containing the CSV files\n",
    "# Filenames to be processed\n",
    "all_char_files = [\n",
    "    \"../Data/hd2014.csv\",\n",
    "    \"../Data/hd2015.csv\",\n",
    "    \"../Data/hd2016.csv\",\n",
    "    \"../Data/hd2017.csv\",\n",
    "    \"../Data/hd2018.csv\",\n",
    "    \"../Data/hd2019.csv\",\n",
    "    \"../Data/hd2020.csv\",\n",
    "    \"../Data/hd2021.csv\",\n",
    "    \"../Data/hd2022.csv\",\n",
    "    \"../Data/HD2023.csv\"\n",
    "]\n",
    "\n",
    "# Read and combine all matched CSV files\n",
    "dfs2 = []\n",
    "for file in all_char_files:\n",
    "    # Read the CSV file\n",
    "    if 'HD2023' in file:\n",
    "        df2 = pd.read_csv(file, low_memory=False)\n",
    "    else:\n",
    "        df2 = pd.read_csv(file, low_memory=False, encoding='latin1')\n",
    "    # Extract the four digits in the filename\n",
    "    match = re.search(r'(\\d{4})', file)\n",
    "    if match:\n",
    "        df2['year'] = match.group(1)\n",
    "    else:\n",
    "        df2['year'] = None\n",
    "    # Clean white space out of column names\n",
    "    df2.columns = df2.columns.str.strip()\n",
    "    dfs2.append(df2)\n",
    "\n",
    "characteristics = pd.concat(dfs2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74a34a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the characteristics data\n",
    "characteristics.drop_duplicates(inplace=True)\n",
    "characteristics.dropna(subset=['UNITID','year'], inplace=True)\n",
    "characteristics['UNITID'] = characteristics['UNITID'].astype(int)\n",
    "characteristics.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5e5c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left merge the characteristics data onto the combined admissions data on 'UNITID'\n",
    "merged_df = pd.merge(combined_df, characteristics, on=['UNITID', 'year'], how='left', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dddd208f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNITID</th>\n",
       "      <th>ADMCON1</th>\n",
       "      <th>ADMCON2</th>\n",
       "      <th>ADMCON3</th>\n",
       "      <th>ADMCON4</th>\n",
       "      <th>ADMCON5</th>\n",
       "      <th>ADMCON6</th>\n",
       "      <th>ADMCON7</th>\n",
       "      <th>ADMCON8</th>\n",
       "      <th>ADMCON9</th>\n",
       "      <th>...</th>\n",
       "      <th>C18ENPRF</th>\n",
       "      <th>C18SZSET</th>\n",
       "      <th>C21BASIC</th>\n",
       "      <th>C21IPUG</th>\n",
       "      <th>C21IPGRD</th>\n",
       "      <th>C21UGPRF</th>\n",
       "      <th>C21ENPRF</th>\n",
       "      <th>C21SZSET</th>\n",
       "      <th>UEIS</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100654</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100663</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100706</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100724</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100751</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UNITID  ADMCON1  ADMCON2  ADMCON3  ADMCON4  ADMCON5  ADMCON6  ADMCON7  \\\n",
       "0  100654        1        2        1        2        3        2        1   \n",
       "1  100663        1        3        1        1        3        3        1   \n",
       "2  100706        1        2        1        1        3        2        1   \n",
       "3  100724        1        3        2        3        3        3        1   \n",
       "4  100751        1        2        1        1        3        3        1   \n",
       "\n",
       "   ADMCON8  ADMCON9  ... C18ENPRF  C18SZSET C21BASIC  C21IPUG C21IPGRD  \\\n",
       "0        1        3  ...      NaN       NaN      NaN      NaN      NaN   \n",
       "1        3        3  ...      NaN       NaN      NaN      NaN      NaN   \n",
       "2        1        3  ...      NaN       NaN      NaN      NaN      NaN   \n",
       "3        1        3  ...      NaN       NaN      NaN      NaN      NaN   \n",
       "4        1        3  ...      NaN       NaN      NaN      NaN      NaN   \n",
       "\n",
       "   C21UGPRF C21ENPRF  C21SZSET UEIS  _merge  \n",
       "0       NaN      NaN       NaN  NaN    both  \n",
       "1       NaN      NaN       NaN  NaN    both  \n",
       "2       NaN      NaN       NaN  NaN    both  \n",
       "3       NaN      NaN       NaN  NaN    both  \n",
       "4       NaN      NaN       NaN  NaN    both  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "924345d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how many rows were matched and how many were not\n",
    "merged_df[\"_merge\"].value_counts()\n",
    "\n",
    "# Drop unmatched rows and the merge indicator column\n",
    "merged_df = merged_df[merged_df[\"_merge\"] == \"both\"].drop(columns=[\"_merge\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c8479d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final combined DataFrame to a CSV file\n",
    "merged_df.to_csv('../Data/combined_admissions_characteristics.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
